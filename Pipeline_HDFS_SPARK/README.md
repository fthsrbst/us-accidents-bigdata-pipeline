# BÃ¼yÃ¼k Veri Pipeline - B SeÃ§eneÄŸi

## UÃ§tan Uca Data Pipeline: HDFS + Hive + Kafka + Spark + MongoDB

Bu proje, BÃ¼yÃ¼k Veri ve AnalitiÄŸi dersi kapsamÄ±nda hazÄ±rlanmÄ±ÅŸ uÃ§tan uca bir veri iÅŸleme pipeline'Ä±dÄ±r.

---

## ğŸ“‹ Ä°Ã§indekiler

1. [Mimari](#mimari)
2. [Gereksinimler](#gereksinimler)
3. [Kurulum](#kurulum)
4. [KullanÄ±m](#kullanÄ±m)
5. [Pipeline BileÅŸenleri](#pipeline-bileÅŸenleri)
6. [Veri Seti](#veri-seti)
7. [Model SonuÃ§larÄ±](#model-sonuÃ§larÄ±)
8. [Web ArayÃ¼zleri](#web-arayÃ¼zleri)

---

## ğŸ—ï¸ Mimari

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          DATA PIPELINE ARCHITECTURE                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚   â”‚  Kaggle  â”‚â”€â”€â”€â”€â–¶â”‚  Kafka   â”‚â”€â”€â”€â”€â–¶â”‚  Spark Streaming â”‚                â”‚
â”‚   â”‚   CSV    â”‚     â”‚ Producer â”‚     â”‚                  â”‚                â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                                               â”‚                          â”‚
â”‚                                               â–¼                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚   â”‚                      HDFS                             â”‚              â”‚
â”‚   â”‚                 (Parquet Format)                      â”‚              â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                              â”‚                                           â”‚
â”‚                              â–¼                                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚   â”‚                    Apache Hive                        â”‚              â”‚
â”‚   â”‚               (Metadata & SQL Query)                  â”‚              â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                              â”‚                                           â”‚
â”‚                              â–¼                                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚   â”‚                   PySpark ML                          â”‚              â”‚
â”‚   â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚              â”‚
â”‚   â”‚         â”‚    kNN      â”‚   K-Means   â”‚                â”‚              â”‚
â”‚   â”‚         â”‚ (Classify)  â”‚  (Cluster)  â”‚                â”‚              â”‚
â”‚   â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚              â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                              â”‚                                           â”‚
â”‚                              â–¼                                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚   â”‚                     MongoDB                           â”‚              â”‚
â”‚   â”‚              (Results & Predictions)                  â”‚              â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’» Gereksinimler

### Sistem Gereksinimleri
- **Ä°ÅŸletim Sistemi:** Windows 10/11, macOS, Linux
- **RAM:** Minimum 8GB (16GB Ã¶nerilir)
- **Disk:** En az 20GB boÅŸ alan
- **CPU:** 4+ Ã§ekirdek Ã¶nerilir

### YazÄ±lÄ±m Gereksinimleri
- Docker Desktop (v20.10+)
- Docker Compose (v2.0+)
- Python 3.8+ (lokal geliÅŸtirme iÃ§in)
- Kaggle hesabÄ± ve API anahtarÄ±

---

## ğŸš€ Kurulum

### 1. Docker Desktop Kurulumu

**Windows:**
1. [Docker Desktop](https://www.docker.com/products/docker-desktop/) indirin
2. Kurulum sihirbazÄ±nÄ± takip edin
3. WSL 2 backend'i etkinleÅŸtirin (Ã¶nerilir)
4. Docker Desktop'Ä± baÅŸlatÄ±n

**DoÄŸrulama:**
```bash
docker --version
docker-compose --version
```

### 2. Kaggle API AnahtarÄ±

1. [Kaggle](https://www.kaggle.com) hesabÄ±nÄ±za giriÅŸ yapÄ±n
2. Profil > Settings > API > Create New Token
3. Ä°ndirilen `kaggle.json` dosyasÄ±nÄ± ÅŸuraya kopyalayÄ±n:
   - Windows: `C:\Users\<kullanÄ±cÄ±>\.kaggle\kaggle.json`
   - macOS/Linux: `~/.kaggle/kaggle.json`

### 3. Servisleri BaÅŸlatma

```bash
# Pipeline_B klasÃ¶rÃ¼ne gidin
cd Pipeline_B

# Docker container'larÄ± baÅŸlatÄ±n
docker-compose up -d

# Servislerin durumunu kontrol edin
docker-compose ps
```

**Ä°lk baÅŸlatma 5-10 dakika sÃ¼rebilir (image'lar indirilirken).**

### 4. Python BaÄŸÄ±mlÄ±lÄ±klarÄ± (Lokal GeliÅŸtirme)

```bash
pip install -r scripts/requirements.txt
```

---

## ğŸ“– KullanÄ±m

### Otomatik Pipeline Ã‡alÄ±ÅŸtÄ±rma

TÃ¼m adÄ±mlarÄ± sÄ±rayla Ã§alÄ±ÅŸtÄ±rmak iÃ§in:

```bash
python scripts/run_pipeline.py
```

### Manuel AdÄ±m AdÄ±m Ã‡alÄ±ÅŸtÄ±rma

```bash
# 1. Veri setini indir
python scripts/download_data.py

# 2. (Opsiyonel) Kafka'ya stream et
python scripts/kafka_producer.py

# 3. HDFS'e yÃ¼kle (batch mode)
python scripts/spark_streaming.py --batch

# 4. Hive tablolarÄ± oluÅŸtur
python scripts/hdfs_to_hive.py

# 5. Veri temizleme
python scripts/data_cleaning.py

# 6. kNN sÄ±nÄ±flandÄ±rma
python scripts/knn_classification.py

# 7. K-Means kÃ¼meleme
python scripts/kmeans_clustering.py

# 8. MongoDB'ye export
python scripts/mongodb_export.py
```

### Jupyter Notebook

```bash
# Jupyter'e eriÅŸim
http://localhost:8888

# notebooks/analysis.ipynb dosyasÄ±nÄ± aÃ§Ä±n
```

---

## ğŸ”§ Pipeline BileÅŸenleri

### 1. Veri Alma (Data Ingestion)
- **Script:** `download_data.py`
- **Kaynak:** Kaggle API
- **Format:** CSV

### 2. Stream Ä°ÅŸleme
- **Script:** `kafka_producer.py`, `spark_streaming.py`
- **Kafka Topic:** `us_accidents`
- **Ã‡Ä±ktÄ±:** HDFS (Parquet)

### 3. Veri Depolama
- **HDFS Path:** `/user/bigdata/accidents`
- **Format:** Parquet (sÄ±kÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ)
- **Hive Database:** `bigdata_db`
- **Hive Table:** `us_accidents`

### 4. Veri Temizleme
- **Script:** `data_cleaning.py`
- **Ä°ÅŸlemler:**
  - Eksik deÄŸer doldurma
  - AykÄ±rÄ± deÄŸer tespiti
  - Feature engineering
  - Standardizasyon

### 5. kNN SÄ±nÄ±flandÄ±rma
- **Script:** `knn_classification.py`
- **Hedef:** Severity (1-4)
- **Metrikler:**
  - Accuracy
  - Precision (Macro/Weighted)
  - Recall (Macro/Weighted)
  - F1-Score (Macro/Weighted)
  - AUC-ROC (Multi-class)

### 6. K-Means KÃ¼meleme
- **Script:** `kmeans_clustering.py`
- **Metrikler:**
  - Silhouette Score
  - Calinski-Harabasz Index
  - Davies-Bouldin Index
- **GÃ¶rselleÅŸtirmeler:**
  - Elbow Curve
  - 2D PCA Projeksiyon
  - KÃ¼me Profilleri
  - CoÄŸrafi DaÄŸÄ±lÄ±m

### 7. MongoDB Export
- **Script:** `mongodb_export.py`
- **Collections:**
  - `model_results`: Model sonuÃ§larÄ±
  - `accidents_sample`: Ã–rnek tahminler
  - `statistics`: Agregat istatistikler
  - `pipeline_metadata`: Pipeline bilgileri

---

## ğŸ“Š Veri Seti

### US Accidents Dataset

- **Kaynak:** [Kaggle](https://www.kaggle.com/datasets/sobhanmoosavi/us-accidents)
- **Boyut:** ~1.5GB (3+ milyon kayÄ±t)
- **DÃ¶nem:** 2016-2023
- **Ã–zellikler:** 47 sÃ¼tun

**Ana Ã–zellikler:**
| Ã–zellik | AÃ§Ä±klama |
|---------|----------|
| Severity | Kaza ciddiyeti (1-4) |
| Start_Lat/Lng | Konum koordinatlarÄ± |
| Temperature | SÄ±caklÄ±k (Â°F) |
| Humidity | Nem (%) |
| Weather_Condition | Hava durumu |
| Traffic_Signal | Trafik Ä±ÅŸÄ±ÄŸÄ± varlÄ±ÄŸÄ± |
| Hour/DayOfWeek | Zaman Ã¶zellikleri |

---

## ğŸ“ˆ Model SonuÃ§larÄ±

### kNN SÄ±nÄ±flandÄ±rma (Beklenen SonuÃ§lar)

| Metrik | DeÄŸer |
|--------|-------|
| Accuracy | ~0.75-0.85 |
| Precision (Macro) | ~0.60-0.70 |
| Recall (Macro) | ~0.55-0.65 |
| F1-Score (Macro) | ~0.57-0.67 |
| AUC-ROC (Macro) | ~0.80-0.90 |

### K-Means KÃ¼meleme (Beklenen SonuÃ§lar)

| Metrik | DeÄŸer |
|--------|-------|
| Optimal k | 4-6 |
| Silhouette Score | ~0.20-0.40 |
| Calinski-Harabasz | ~1000-5000 |
| Davies-Bouldin | ~1.0-2.0 |

---

## ğŸŒ Web ArayÃ¼zleri

| Servis | URL | KullanÄ±cÄ± | Åifre |
|--------|-----|-----------|-------|
| HDFS NameNode | http://localhost:9870 | - | - |
| Spark Master | http://localhost:8080 | - | - |
| Spark Jobs | http://localhost:4040 | - | - |
| Hive Server | http://localhost:10002 | - | - |
| MongoDB Express | http://localhost:8082 | admin | admin123 |
| Jupyter Notebook | http://localhost:8888 | - | - |

---

## ğŸ“ Dosya YapÄ±sÄ±

```
Pipeline_B/
â”œâ”€â”€ docker-compose.yml          # Docker servisleri
â”œâ”€â”€ README.md                   # Bu dosya
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ hive-site.xml          # Hive konfigÃ¼rasyonu
â”‚   â””â”€â”€ environment.env        # Ortam deÄŸiÅŸkenleri
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/                   # Ham veri (CSV)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_data.py       # Veri indirme
â”‚   â”œâ”€â”€ kafka_producer.py      # Kafka producer
â”‚   â”œâ”€â”€ spark_streaming.py     # Spark streaming
â”‚   â”œâ”€â”€ hdfs_to_hive.py        # Hive tablo oluÅŸturma
â”‚   â”œâ”€â”€ data_cleaning.py       # Veri temizleme
â”‚   â”œâ”€â”€ knn_classification.py  # kNN modeli
â”‚   â”œâ”€â”€ kmeans_clustering.py   # K-Means modeli
â”‚   â”œâ”€â”€ mongodb_export.py      # MongoDB export
â”‚   â”œâ”€â”€ run_pipeline.py        # Pipeline orchestrator
â”‚   â””â”€â”€ requirements.txt       # Python baÄŸÄ±mlÄ±lÄ±klarÄ±
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ analysis.ipynb         # Analiz notebook'u
â””â”€â”€ results/
    â””â”€â”€ visualizations/        # Grafik Ã§Ä±ktÄ±larÄ±
```

---

## ğŸ›‘ Servisleri Durdurma

```bash
# TÃ¼m container'larÄ± durdur
docker-compose down

# Volume'larÄ± da sil (veri kaybÄ±!)
docker-compose down -v
```

---

## ğŸ” Sorun Giderme

### Docker bellek hatasÄ±
```bash
# Docker Desktop ayarlarÄ±ndan RAM'i artÄ±rÄ±n (en az 8GB)
```

### Kafka baÄŸlantÄ± hatasÄ±
```bash
# Kafka'nÄ±n baÅŸlamasÄ±nÄ± bekleyin
docker-compose logs -f kafka
```

### HDFS yazma hatasÄ±
```bash
# HDFS'i kontrol edin
docker exec -it namenode hdfs dfs -ls /
```

### MongoDB baÄŸlantÄ± hatasÄ±
```bash
# MongoDB durumunu kontrol edin
docker exec -it mongodb mongosh --eval "db.adminCommand('ping')"
```

---

## ğŸ‘¥ Proje Ekibi

- **Ã–ÄŸrenci 1:** [Ä°sim]
- **Ã–ÄŸrenci 2:** [Ä°sim]

**Ders:** BÃ¼yÃ¼k Veri ve AnalitiÄŸi  
**DÃ¶nem:** 2024-2025 GÃ¼z

---

## ğŸ“š Kaynaklar

- [Apache Spark Documentation](https://spark.apache.org/docs/latest/)
- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [Apache Hive Documentation](https://hive.apache.org/)
- [MongoDB Documentation](https://docs.mongodb.com/)
- [US Accidents Dataset](https://www.kaggle.com/datasets/sobhanmoosavi/us-accidents)
